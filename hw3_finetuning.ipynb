{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "sentiment_dataset = load_dataset('carblacac/twitter-sentiment-analysis')\n",
    "\n",
    "# Access the training and testing sets directly\n",
    "train_dataset = sentiment_dataset['train']\n",
    "test_dataset = sentiment_dataset['test']\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "train_df = train_dataset.to_pandas()\n",
    "test_df = test_dataset.to_pandas()\n",
    "\n",
    "# Select the first 1000 rows of the train dataset\n",
    "train_df = train_df[:30000] #30000\n",
    "\n",
    "# Select the first 50 rows of the test dataset\n",
    "test_df = test_df[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two detailed sets of instructions\n",
    "instructions1 = \"\"\"\n",
    "Please read the tweet provided below. Your task is to analyze the content and context of the tweet to determine whether it \n",
    "expresses a positive or negative sentiment. Consider the use of emotive language, punctuation, and any emoticons used. \n",
    "Classify the tweet accordingly as either '1' if it conveys a favorable opinion or emotion, or '0' if it \n",
    "expresses an unfavorable opinion or emotion.\n",
    "### Tweet: {tweet}\n",
    "### Sentiment: {sentiment}\n",
    "\"\"\"\n",
    "\n",
    "instructions2 = \"\"\"\n",
    "Examine the following tweet carefully. Assess whether the tweet has a positive or negative tone based on the wording, \n",
    "sentence structure, and any emoticons present. If the tweet suggests a positive outlook or a pleasant emotional state, \n",
    "classify it as '1'. Conversely, if the tweet indicates dissatisfaction or unhappiness, classify it as '0'.\n",
    "### Tweet: {tweet}\n",
    "### Sentiment: {sentiment}\n",
    "\"\"\"\n",
    "\n",
    "# Function to append instructions to each row\n",
    "def add_instructions(df):\n",
    "    df['Instruction1'] = df.apply(lambda x: instructions1.format(tweet=x['text'], sentiment=x['feeling']), axis=1)\n",
    "    df['Instruction2'] = df.apply(lambda x: instructions2.format(tweet=x['text'], sentiment=x['feeling']), axis=1)\n",
    "    return df\n",
    "\n",
    "# Apply instructions to the full train and test datasets\n",
    "train_df = add_instructions(train_df)\n",
    "test_df = add_instructions(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please read the tweet provided below. Your task is to analyze the content and context of the tweet to determine whether it \n",
      "expresses a positive or negative sentiment. Consider the use of emotive language, punctuation, and any emoticons used. \n",
      "Classify the tweet accordingly as either '1' if it conveys a favorable opinion or emotion, or '0' if it \n",
      "expresses an unfavorable opinion or emotion.\n",
      "### Tweet: @fa6ami86 so happy that salman won.  btw the 14sec clip is truely a teaser\n",
      "### Sentiment: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[0]['Instruction1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examine the following tweet carefully. Assess whether the tweet has a positive or negative tone based on the wording, \n",
      "sentence structure, and any emoticons present. If the tweet suggests a positive outlook or a pleasant emotional state, \n",
      "classify it as '1'. Conversely, if the tweet indicates dissatisfaction or unhappiness, classify it as '0'.\n",
      "### Tweet: @fa6ami86 so happy that salman won.  btw the 14sec clip is truely a teaser\n",
      "### Sentiment: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[0]['Instruction2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "new_model = '/work/gns938/nlp_hw3/Mistral-sentiment-fine-tuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.35s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2, #4\n",
    "    gradient_accumulation_steps=8, #16\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25, #100\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\" #all\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"Instruction1\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 1:37:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.453900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.827900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.446200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.825800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.408700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.415300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.409900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.777400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.401900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.397300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.751400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.772500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.778800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.777200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.770600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.421600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.759300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.779200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.781800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.760100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.429500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.759400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.427800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>0.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.426800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.407400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>0.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.416100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>0.749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.396200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>0.579900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/work/gns938/nlp_hw3/Mistral-sentiment-fine-tuned/tokenizer_config.json',\n",
       " '/work/gns938/nlp_hw3/Mistral-sentiment-fine-tuned/special_tokens_map.json',\n",
       " '/work/gns938/nlp_hw3/Mistral-sentiment-fine-tuned/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "split_datasets_alpaca = alpaca_dataset['train'].train_test_split(test_size=0.02, seed=42)\n",
    "\n",
    "# Access the training and testing sets directly\n",
    "train_dataset_alpaca = split_datasets_alpaca['train']\n",
    "test_dataset_alpaca = split_datasets_alpaca['test']\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "train_df_alpaca = train_dataset_alpaca.to_pandas()\n",
    "test_df_alpaca = test_dataset_alpaca.to_pandas()\n",
    "\n",
    "# Select the first 1000 rows of the train dataset\n",
    "train_df_alpaca = train_df_alpaca[:30000]\n",
    "\n",
    "# Select the first 50 rows of the test dataset\n",
    "test_df_alpaca = test_df_alpaca[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the sentiment dataset to match the alpaca dataset structure\n",
    "train_df_renamed = train_df.rename(columns={\n",
    "    'Instruction1': 'text',\n",
    "    'text': 'instruction',\n",
    "    'feeling': 'output'\n",
    "})\n",
    "\n",
    "# Convert the 'output' column to string to match expected data types\n",
    "train_df_renamed['output'] = train_df_renamed['output'].astype(str)\n",
    "\n",
    "# Add the missing 'input' column filled with empty strings for the sentiment dataset\n",
    "train_df_renamed['input'] = ''\n",
    "\n",
    "# Reorder columns to match the alpaca dataset\n",
    "train_df_restructured = train_df_renamed[['instruction', 'input', 'output', 'text']]\n",
    "\n",
    "# Concatenate the alpaca dataset and the restructured sentiment dataset\n",
    "combined_train_dataset = pd.concat([train_df_alpaca, train_df_restructured], ignore_index=True)\n",
    "\n",
    "# Optionally, convert the combined pandas dataframe back to a Hugging Face dataset if needed\n",
    "combined_train_hf_dataset = Dataset.from_pandas(combined_train_dataset)\n",
    "\n",
    "# Print the combined dataset to verify\n",
    "# print(combined_train_dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Name three computer programs which can be used...</td>\n",
       "      <td></td>\n",
       "      <td>Three computer programs which can be used to c...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Write pseudocode for a program to calculate th...</td>\n",
       "      <td></td>\n",
       "      <td>// Function to calculate average of numbers in...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Name an alternative to using money as a currency.</td>\n",
       "      <td></td>\n",
       "      <td>Bartering is an alternative to using money as ...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Provide three examples of chemical reactions.</td>\n",
       "      <td></td>\n",
       "      <td>1. Combustion: C8H18 + O2 --&gt; CO2 + H2O\\n2. Ac...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Generate a funny icebreaker for a group of fri...</td>\n",
       "      <td></td>\n",
       "      <td>What do you call an alligator in a vest? \\nAns...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>@fa6ami86 so happy that salman won.  btw the 1...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>\\nPlease read the tweet provided below. Your t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001</th>\n",
       "      <td>@phantompoptart .......oops.... I guess I'm ki...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>\\nPlease read the tweet provided below. Your t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002</th>\n",
       "      <td>@bradleyjp decidedly undecided. Depends on the...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>\\nPlease read the tweet provided below. Your t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30003</th>\n",
       "      <td>@Mountgrace lol i know! its so frustrating isn...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>\\nPlease read the tweet provided below. Your t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30004</th>\n",
       "      <td>@kathystover Didn't go much of any where - Lif...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>\\nPlease read the tweet provided below. Your t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction input  \\\n",
       "29995  Name three computer programs which can be used...         \n",
       "29996  Write pseudocode for a program to calculate th...         \n",
       "29997  Name an alternative to using money as a currency.         \n",
       "29998      Provide three examples of chemical reactions.         \n",
       "29999  Generate a funny icebreaker for a group of fri...         \n",
       "30000  @fa6ami86 so happy that salman won.  btw the 1...         \n",
       "30001  @phantompoptart .......oops.... I guess I'm ki...         \n",
       "30002  @bradleyjp decidedly undecided. Depends on the...         \n",
       "30003  @Mountgrace lol i know! its so frustrating isn...         \n",
       "30004  @kathystover Didn't go much of any where - Lif...         \n",
       "\n",
       "                                                  output  \\\n",
       "29995  Three computer programs which can be used to c...   \n",
       "29996  // Function to calculate average of numbers in...   \n",
       "29997  Bartering is an alternative to using money as ...   \n",
       "29998  1. Combustion: C8H18 + O2 --> CO2 + H2O\\n2. Ac...   \n",
       "29999  What do you call an alligator in a vest? \\nAns...   \n",
       "30000                                                  0   \n",
       "30001                                                  0   \n",
       "30002                                                  1   \n",
       "30003                                                  1   \n",
       "30004                                                  1   \n",
       "\n",
       "                                                    text  \n",
       "29995  Below is an instruction that describes a task....  \n",
       "29996  Below is an instruction that describes a task....  \n",
       "29997  Below is an instruction that describes a task....  \n",
       "29998  Below is an instruction that describes a task....  \n",
       "29999  Below is an instruction that describes a task....  \n",
       "30000  \\nPlease read the tweet provided below. Your t...  \n",
       "30001  \\nPlease read the tweet provided below. Your t...  \n",
       "30002  \\nPlease read the tweet provided below. Your t...  \n",
       "30003  \\nPlease read the tweet provided below. Your t...  \n",
       "30004  \\nPlease read the tweet provided below. Your t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows 995 up to 1005 of the combined_train_dataset\n",
    "combined_train_dataset.iloc[29995:30005]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset_mixed = Dataset.from_pandas(combined_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dset_mixed,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_mixed = '/work/gns938/nlp_hw3/Mistral-mixed-fine-tuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 3:12:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.720500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.659900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.879500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.650600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.612600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.590300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.832100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.592600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.836700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.618600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.820800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.835600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.615800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.826200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.612400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.607700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.794100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.608100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.822400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.634500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.830200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.840100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.836300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.599400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.592900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.838200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.604800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.615200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.828700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.842300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.595100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.864800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>0.820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.561200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>0.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>0.813200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.614600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>0.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.600700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>0.825700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>0.833200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.600400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>0.832100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>0.836900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>0.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>0.806200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.618100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>0.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>0.818900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>0.840600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>0.821500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.590500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>0.828100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>0.823600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.609900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>0.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>0.815300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.601800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>0.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.578800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>0.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>0.841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>0.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>0.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>0.836700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>0.789900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>0.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>0.813300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.616400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>0.828700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>0.814500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>0.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>0.824600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>0.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.620800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>0.817800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>0.814300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>0.830600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.594100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>0.800300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.597400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>0.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.596600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>0.802200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.600400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>0.793600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.596100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>0.834100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.596300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/work/gns938/nlp_hw3/Mistral-mixed-fine-tuned/tokenizer_config.json',\n",
       " '/work/gns938/nlp_hw3/Mistral-mixed-fine-tuned/special_tokens_map.json',\n",
       " '/work/gns938/nlp_hw3/Mistral-mixed-fine-tuned/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.model.save_pretrained(new_model_mixed)\n",
    "trainer.tokenizer.save_pretrained(new_model_mixed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
